{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293ec4e3",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6eec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functions import Affine, ReLU, get_epsilon, get_stop, create_constraints_dictionaries, update_layer_0, check_activation_functions, create_extra_layer, calculate_previous_layer_number, get_correctly_classified_pictures, update_upper_lower, propagate, sum_arrays, check_specification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7480994",
   "metadata": {},
   "source": [
    "### Create dictionaries for weights, biases and activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ca6f590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from json import loads\n",
    "\n",
    "# File containing the network.\n",
    "net_file = open(\"custom_relu.tf\", mode='r')\n",
    "net_file_list = list(net_file)\n",
    "\n",
    "# Empty lists are created for the weights, biases and activation functions.\n",
    "weights_list = []\n",
    "biases_list = []\n",
    "activations_list = []\n",
    "\n",
    "# weights_list, activations_list and biases_list are updated dinamically by reading the lines of the network file.\n",
    "for i in range(0, (len(net_file_list) - 2), 3):\n",
    "    activations_list.append(net_file_list[i][:-1])\n",
    "    weights_list.append(net_file_list[i+1][:-1])\n",
    "    biases_list.append(net_file_list[i+2][:-1])\n",
    "\n",
    "# Check that all activation functions are either ReLU or Affine.\n",
    "check_activation_functions(activations_list)\n",
    "    \n",
    "# The lists become dictionaries, where layer_i is the key for the array of weights/biases/activations for that layer.\n",
    "weights = {}\n",
    "biases = {}\n",
    "activations = {}\n",
    "# Iterate over all layers.\n",
    "for i in range(0, len(weights_list)):\n",
    "    weights[\"layer%s\" %(i + 1)] = np.array(loads(weights_list[i])) # json.loads turns the string into a (nested) list.\n",
    "    biases[\"layer%s\" %(i + 1)] = np.array(loads(biases_list[i]))\n",
    "    activations[\"layer%s\" %(i + 1)] = activations_list[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2de0d2",
   "metadata": {},
   "source": [
    "### Create data structures for the input and output ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75838d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import *\n",
    "\n",
    "dataset = \"example.csv\"\n",
    "\n",
    "# The picture, stored in the csv file, is read and saved in pic. It is of type _io.TextIOWrapper.\n",
    "pic = open(dataset, mode='r')\n",
    "\n",
    "# input_values is a list of strings, containing the first line of the csv file.\n",
    "picture1 = (pic.readline()).rstrip().split(\",\")\n",
    "\n",
    "# Create a list with the first column of the csv file.\n",
    "data = read_csv(dataset)\n",
    "output_column = data[picture1[0]].tolist()\n",
    "# Prepend the first element to the list, since it was lost. Transform output_column in an array.\n",
    "output_column.insert(0, int(picture1[0]))\n",
    "output_column = np.array(output_column)\n",
    "\n",
    "# Remove the first element from input_values, since it is the output label from the first line.\n",
    "picture1.pop(0)\n",
    "\n",
    "# Create the input dictionary\n",
    "\n",
    "input_dic = {}\n",
    "counter = 1\n",
    "input_dic[\"picture1\"] = np.array(list(map(int, picture1)))/255 # / 255 to normalize.\n",
    "\n",
    "# All lines (minus their first element, which is the output) are read as strings.\n",
    "for line in pic.readlines():\n",
    "    \n",
    "    counter = counter + 1\n",
    "    # Lines become arrays of integers and are put in the dictionary as values of the respective picture (which is the key).\n",
    "    input_dic[\"picture%s\" %(counter)] = np.array(list(map(int, (line.rstrip().split(\",\")[1:]))))/255 # /255 to normalize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0264f3",
   "metadata": {},
   "source": [
    "### Calculate the output of the network for each picture and the percentage of pictures it classifies correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2597b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of flags. 1 (0) will mean that the picture corresponding to that index was (not) classified correctly.\n",
    "correctly_classified = np.zeros(len(output_column), dtype = int)\n",
    "\n",
    "# Iterate over all pictures.\n",
    "for picture in input_dic:\n",
    "    \n",
    "    outputarray = input_dic[picture]\n",
    "    \n",
    "    # Calculate the output of the neural network for the current picture.\n",
    "    for layer in weights:\n",
    "        if (activations[layer] == \"Affine\"):\n",
    "            outputarray = Affine(outputarray, weights[layer], biases[layer])\n",
    "        else:\n",
    "            outputarray = ReLU(outputarray, weights[layer], biases[layer])\n",
    "            \n",
    "    # If the current picture was classified correctly, update the array \"correctly_classified\".\n",
    "    # To do this, check whether the greatest element of \"outputarray\" is at the index equal to the label of the respective picture.\n",
    "    if (np.amax(outputarray) == outputarray[output_column[int([(s) for s in picture.split(\"e\") if s.isdigit()][0]) - 1]]):\n",
    "        correctly_classified[int([(s) for s in picture.split(\"e\") if s.isdigit()][0]) - 1] = 1\n",
    "\n",
    "# Calculate the percentage of correctly classified pictures.\n",
    "correctness_basic = ((np.sum(correctly_classified, dtype = int)) / correctly_classified.size) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbae5303",
   "metadata": {},
   "source": [
    "### Get inputs from the user and do some preparations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb7075fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the noise interval centred on each pixel will be 2ε. Please, write a value for ε: 1\n",
      "Please, write the number of the layer you want to stop and take the concrete bounds at when calculating the new upper and lower bounds. If you want maximum precision and thus to select the concrete bounds at the input layer, you can write 0. If an invalid number is provided, it will be truncated to make it integer.0\n"
     ]
    }
   ],
   "source": [
    "# Have the user provide an ε value, determining the length of the noise interval centred on each pixel.\n",
    "epsilon = get_epsilon()\n",
    "\n",
    "# Have the user provide the number of the layer at which they want to use the concrete bounds when calculating\n",
    "# new upper and lower bounds.\n",
    "stop = get_stop()\n",
    "\n",
    "# Work out the dictionary of correctly classified pictures with the correct output neuron.\n",
    "correctly_classified_pictures = get_correctly_classified_pictures(correctly_classified, output_column)\n",
    "\n",
    "correct_array = np.zeros(len(correctly_classified_pictures), dtype = int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603fa2ce",
   "metadata": {},
   "source": [
    "### Perform abstract analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cf4252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = -1\n",
    "from copy import deepcopy\n",
    "\n",
    "# Loop over all correctly classified pictures.\n",
    "for picture in correctly_classified_pictures:\n",
    "    \n",
    "    # Create dictionaries for polyhedral constraints and upper and lower bounds.\n",
    "    constraints = create_constraints_dictionaries(weights, activations)\n",
    "    upper_lower_bounds = constraints[0]\n",
    "    poly_constraints = constraints[1]\n",
    "    # Given a picture, fill in the values for the input layer in the dictionary of upper and lower bounds.\n",
    "    update_layer_0(picture, input_dic, upper_lower_bounds, epsilon)\n",
    "    \n",
    "    # Calculate upper and lower bounds and polyhedral constraints for all neurons in all layers.\n",
    "    for layer in weights:       \n",
    "        propagate(layer, weights, poly_constraints, biases, upper_lower_bounds, activations, stop)\n",
    "    \n",
    "    counter = counter + 1\n",
    "    \n",
    "    # Check the specification.\n",
    "    check_specification(upper_lower_bounds, correctly_classified_pictures, picture, counter, correct_array, poly_constraints, stop)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92889671",
   "metadata": {},
   "source": [
    "### Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721eca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pictures classified correctly before the analysis: 1\n",
      "Number of pictures classified correctly after the analysis: 1\n",
      "Percentage of pictures classified correctly after the analysis, over the pictures that were classified correcly before it: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of pictures classified correctly before the analysis: {np.sum(correctly_classified)}\")\n",
    "print(\"Number of pictures classified correctly after the analysis:\", np.sum(correct_array, dtype = int))\n",
    "print(\"Percentage of pictures classified correctly after the analysis, over the pictures that \" +\\\n",
    "      f\"were classified correcly before it: {((np.sum(correct_array, dtype = int)) / correct_array.size) * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
